Рассчитаем оценки качества классификации на датасете Oranics:
1) confusion matrix - матрица ошибок
Необходимо ввести важную концепцию для описания метрик Accuracy, Recall,
Presicion в терминах ошибок классификации.
Ошибки классификации бывают двух видов: False Negative (FN) и False Positive (FP)
True Positive - 4629
True Negative - 704
False Positive - 389
False Negative - 945

2) Mean consequential error = 0,7999 - доля правильных ответов алгоритма

3) Точность(precision) = 0,644 - доля объектов, названных классификатором положительными 
и при этом действительно являющимися положительными

4) Полнота(recall) = 0,427 - доля объектов положительного класса из 
всех объектов положительного класса 

4) f-мера -  среднее гармоническое precision и recall = 0,51
F-мера достигает максимума при полноте и точности, равными единице, 
и близка к нулю, если один из аргументов близок к нулю.

5) Balanced accuracy = 0,675 - среднее количество recall, полученных по каждому классу

5) Matthews correlation coef = 0, 407 - Коэффициент +1 представляет собой идеальный прогноз, 0 - средний случайный прогноз, а -1 - обратный прогноз

6) Cohen's Kappa - 0,394 - оценка, которая выражает уровень согласия между двумя аннотаторами по проблеме классификации
Максимальное значение означает полное согласие; ноль или ниже означает случайное соглашение.

Roc-кривая:
Значение AUC=0,79
Чем больше это значение, тем лучше модель